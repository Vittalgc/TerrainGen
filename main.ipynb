{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d3efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14086944-bc37-458b-929c-43ba4db834d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476280b8-af7d-48ed-86bf-489ef62db60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.optimizers.experimental import RMSprop\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d7a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_data_generator(dir_path, batch_size):\n",
    "    # Get the list of all files in the directory\n",
    "    file_list = [f for f in os.listdir(dir_path) if f.endswith('.png')]\n",
    "    num_files = len(file_list)\n",
    "\n",
    "    while True:\n",
    "        # shuffle\n",
    "        np.random.shuffle(file_list)\n",
    "\n",
    "        for i in range(0, num_files, batch_size):\n",
    "            # get a list of filenames of a batch\n",
    "            batch_files = file_list[i : i + batch_size]\n",
    "\n",
    "            batch_images = []\n",
    "            batch_IMRS = []\n",
    "\n",
    "            for file in batch_files:\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                # read the image and generate IMR\n",
    "                img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                arr = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "                height, width = arr.shape\n",
    "                # Assuming a resolution of 128 x 128\n",
    "                grid_width, grid_height = width // 4, height // 4\n",
    "\n",
    "                imr_values = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "                IMR = np.zeros((grid_height, grid_width))\n",
    "\n",
    "                for i in range(grid_height):\n",
    "                    for j in range(grid_width):\n",
    "                        start_i = i * 4\n",
    "                        end_i = min((i + 1) * 4, height)\n",
    "                        start_j = j * 4\n",
    "                        end_j = min((j + 1) * 4, width)\n",
    "\n",
    "                        area = arr[start_i:end_i, start_j:end_j]\n",
    "\n",
    "                        if area.size > 0:\n",
    "                            avg_brightness = np.mean(area)\n",
    "\n",
    "                            closest_values = sorted(imr_values, key=lambda x: abs(avg_brightness - x))[:2]\n",
    "                            assigned_value = random.choice(closest_values)\n",
    "                            IMR[i][j] = assigned_value\n",
    "                \n",
    "                IMR_reshaped = IMR.reshape(32, 32, 1)\n",
    "                img = cv2.normalize(img, None, alpha=-1, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                batch_images.append(img)\n",
    "                batch_IMRS.append(IMR_reshaped)\n",
    "            \n",
    "            yield np.array(batch_images), np.array(batch_IMRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16c747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(package=\"lossfunc\", name=\"wasserstein_loss\")\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.keras.backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea788fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    # IMR Input\n",
    "    input1 = layers.Input(shape=(32, 32, 1))\n",
    "    x1 = layers.Conv2DTranspose(128, kernel_size=3, dilation_rate=2, padding='same')(input1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.LeakyReLU()(x1)\n",
    "    # Noise vector Input\n",
    "    input2 = layers.Input(shape=(128, 8, 1))\n",
    "    x2 = layers.Reshape((32, 32, 1))(input2)\n",
    "    # concatenate the layers\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "    # upsample\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    final = layers.Conv2DTranspose(1, kernel_size=5, strides=1, padding='same', activation='tanh')(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    # x = layers.LeakyReLU()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[input1, input2], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5852a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conversion_critic():\n",
    "    # IMR Input\n",
    "    input1 = layers.Input(shape=(32, 32, 1))\n",
    "    x1 = layers.Conv2D(32, kernel_size=4, padding='same')(input1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.LeakyReLU()(x1)\n",
    "\n",
    "    x1 = layers.Conv2D(32, kernel_size=4, padding='same')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.LeakyReLU()(x1) # 32x32x32\n",
    "\n",
    "    # Input from Generator\n",
    "    input2 = layers.Input(shape=(128, 128, 1))\n",
    "    x2 = layers.Conv2D(32, kernel_size=3, dilation_rate=2, padding='same')(input2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.LeakyReLU()(x2)\n",
    "\n",
    "    x2 = layers.Conv2D(32, kernel_size=4, strides=2, padding='same')(x2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.LeakyReLU()(x2)\n",
    "\n",
    "    x2 = layers.Conv2D(32, kernel_size=4, strides=2, padding='same')(x2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.LeakyReLU()(x2) # 32x32x32\n",
    "\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "    x = layers.Conv2D(32, kernel_size=4, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, kernel_size=4, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, kernel_size=5, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    final = layers.Dense(1)(x)\n",
    "\n",
    "    critic = tf.keras.Model(inputs=[input1, input2], outputs=final)\n",
    "    critic.compile(loss=wasserstein_loss, optimizer=RMSprop(learning_rate=0.00025))\n",
    "    return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec99e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_realism_critic():\n",
    "    # Input from Generator\n",
    "    input_layer = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    x = layers.Conv2D(256, kernel_size=4, strides=1)(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=4, strides=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, kernel_size=4, strides=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, kernel_size=4, strides=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, kernel_size=4, strides=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    final = layers.Dense(1)(x)\n",
    "\n",
    "    critic = tf.keras.Model(inputs=input_layer, outputs=final)\n",
    "    critic.compile(loss=wasserstein_loss, optimizer=RMSprop(learning_rate=0.0005))\n",
    "    return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec6264d-56d5-4b66-bfe0-ac0e68314108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model for ConversionGAN\n",
    "def define_ConvGAN(generator, critic):\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    imr_input = layers.Input(shape=(32, 32, 1))\n",
    "    z_input = layers.Input(shape=(128, 8, 1))\n",
    "    g = generator([imr_input, z_input])\n",
    "    c = critic([imr_input, g])\n",
    "    model = tf.keras.Model(inputs=[imr_input, z_input], outputs=c, name=\"ConversionGAN\")\n",
    "    model.compile(loss=wasserstein_loss, optimizer=RMSprop(learning_rate=0.00025))\n",
    "    return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9d1719-0319-412e-bec2-4a8e999b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model for RealismGAN\n",
    "def define_RealGAN(generator, critic):\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    imr_input = layers.Input(shape=(32, 32, 1))\n",
    "    z_input = layers.Input(shape=(128, 8, 1))\n",
    "    g = generator([imr_input, z_input])\n",
    "    c = critic(g)\n",
    "    model = tf.keras.Model(inputs=[imr_input, z_input], outputs=c, name=\"RealismGAN\")\n",
    "    model.compile(loss=wasserstein_loss, optimizer=RMSprop(learning_rate=0.0005))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6e085a-3bb6-4c8d-a2f4-e1f5d3c69f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vis_imrs(dir_path):\n",
    "    file_list = [f for f in os.listdir(dir_path) if f.endswith('.png')]\n",
    "    num_files = len(file_list)\n",
    "\n",
    "    vis_IMRS = []\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "\n",
    "        # read the image and generate IMR\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        arr = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        height, width = arr.shape\n",
    "        # Assuming a resolution of 128 x 128\n",
    "        grid_width, grid_height = width // 4, height // 4\n",
    "\n",
    "        imr_values = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "        IMR = np.zeros((grid_height, grid_width))\n",
    "\n",
    "        for i in range(grid_height):\n",
    "            for j in range(grid_width):\n",
    "                start_i = i * 4\n",
    "                end_i = min((i + 1) * 4, height)\n",
    "                start_j = j * 4\n",
    "                end_j = min((j + 1) * 4, width)\n",
    "\n",
    "                area = arr[start_i:end_i, start_j:end_j]\n",
    "\n",
    "                if area.size > 0:\n",
    "                    avg_brightness = np.mean(area)\n",
    "\n",
    "                    closest_values = sorted(imr_values, key=lambda x: abs(avg_brightness - x))[:2]\n",
    "                    assigned_value = random.choice(closest_values)\n",
    "                    IMR[i][j] = assigned_value\n",
    "                \n",
    "        IMR_reshaped = IMR.reshape(32, 32, 1)\n",
    "        vis_IMRS.append(IMR_reshaped)\n",
    "    return np.array(vis_IMRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca37530-6861-4a8c-98e6-6cce101e2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, imrs, z_vectors, n_samples):\n",
    "    X = generator.predict([imrs, z_vectors], verbose=0)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2b8074-2dce-4b63-aea2-877fceabbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(step, g_model, c_critic, r_critic, imrs, z_vectors, n_samples=10):\n",
    "    plots_path = './Model/plots/'\n",
    "    weights_path = './Model/savedModel/Generator/'\n",
    "    critics_weights_path = './Model/savedModel/Critics/'\n",
    "    X, _ = generate_fake_samples(g_model, imrs, z_vectors, n_samples)\n",
    "    X = (X + 1) / 2.0\n",
    "    fig, axs = pyplot.subplots(2, 5, figsize=(10, 4))\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        img = pyplot.imread(X[i]) if isinstance(X[i], str) else X[i]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    pyplot.tight_layout()\n",
    "    \n",
    "    # save plot to file\n",
    "    filename1 = 'generated_plot_%04d.png' % (step + 1)\n",
    "    pyplot.savefig(os.path.join(plots_path, filename1))\n",
    "    pyplot.clf()\n",
    "    pyplot.close()\n",
    "\n",
    "    # save the models\n",
    "    filename2 = 'model_%04d.tf' % (step + 1)\n",
    "    c_critic_fname = 'conv_%04d.tf' % (step + 1)\n",
    "    r_critic_fname = 'real_%04d.tf' % (step + 1)\n",
    "    g_model.save(os.path.join(weights_path, filename2))\n",
    "    c_critic.save(os.path.join(critics_weights_path, c_critic_fname))\n",
    "    r_critic.save(os.path.join(critics_weights_path, r_critic_fname))\n",
    "    \n",
    "    print('Saved: %s, %s, %s and %s' % (filename1, filename2, c_critic_fname, r_critic_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dd1be35-e230-460c-aaa7-c4d89156f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(c1_hist, c2_hist, r1_hist, r2_hist, gc_hist, gr_hist):\n",
    "    losses_path = './Model/loss/'\n",
    "    pyplot.plot(c1_hist, label='critic_real')\n",
    "    pyplot.plot(c2_hist, label='critic_fake')\n",
    "    pyplot.plot(gc_hist, label='generator')\n",
    "    pyplot.legend()\n",
    "    filename1 = 'ConversionGAN_line_plot_loss.png'\n",
    "    pyplot.savefig(os.path.join(losses_path, filename1))\n",
    "    pyplot.clf()\n",
    "\n",
    "    pyplot.plot(r1_hist, label='critic_real')\n",
    "    pyplot.plot(r2_hist, label='critic_fake')\n",
    "    pyplot.plot(gr_hist, label='generator')\n",
    "    pyplot.legend()\n",
    "    filename2 = 'RealismGAN_line_plot_loss.png'\n",
    "    pyplot.savefig(os.path.join(losses_path, filename2))\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf668c-033e-4bb6-81c4-9e9249d7b71a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Newer train_gan function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e87d6df-387f-41b8-b8da-ff652f2aef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(generator, conversion_critic, realism_critic, ConvGAN, RealGAN, vis_imr, start, epochs, n_critic=2, batch_size=32):\n",
    "    \n",
    "    half_batch = batch_size // 2\n",
    "    dir_path = './Tiles/Train/' \n",
    "    filelist = os.listdir(dir_path)\n",
    "    num_files = len(filelist)\n",
    "    steps_per_epoch = num_files // batch_size\n",
    "\n",
    "    conv1_hist, conv2_hist, real1_hist, real2_hist, gc_hist, gr_hist = list(), list(), list(), list(), list(), list() \n",
    "    \n",
    "    # Initialize the custom data generator\n",
    "    data_generator = cust_data_generator(dir_path, batch_size)\n",
    "    vis_vectors = np.random.normal(-1, 1, (10, 128, 8, 1))\n",
    "    for epoch in range(start, epochs):\n",
    "        c1_tmp, c2_tmp, r1_tmp, r2_tmp, gc_tmp, gr_tmp = list(), list(), list(), list(), list(), list()\n",
    "        \n",
    "        # iterate batch by batch\n",
    "        vis = True\n",
    "        for step in range(steps_per_epoch): \n",
    "            # get a batch of real images and imrs\n",
    "            l = next(data_generator)\n",
    "            x_real, imrs = l[0], l[1]\n",
    "\n",
    "            # generate a batch of fake images from the batch of imrs and z_vectors\n",
    "            z_vectors = np.random.normal(-1, 1, (batch_size, 128, 8, 1))\n",
    "            x_fake, y_fake = generate_fake_samples(generator, imrs, z_vectors, n_samples=batch_size)\n",
    "\n",
    "            # call test_on_batch to get loss of the critics without updating their weights in the process\n",
    "            c_loss = conversion_critic.test_on_batch([imrs, x_fake], y_fake)\n",
    "            r_loss = realism_critic.test_on_batch(x_fake, y_fake)\n",
    "            \n",
    "            critic = 'Realism'\n",
    "\n",
    "            # choose the critic to be trained in this batch\n",
    "            if (c_loss > (2 * r_loss)):\n",
    "                C = conversion_critic\n",
    "                critic = 'Conversion'\n",
    "            else:\n",
    "                C = realism_critic\n",
    "                critic = 'Realism'\n",
    "                \n",
    "            for i in range(n_critic):\n",
    "                start = i * half_batch\n",
    "                end = (i + 1) * half_batch\n",
    "                \n",
    "                # Half a batch of all the inputs\n",
    "                imr = imrs[start:end]\n",
    "                real_images = x_real[start:end]\n",
    "                fake_images = x_fake[start:end]\n",
    "                \n",
    "                y_real = -np.ones((half_batch, 1))\n",
    "                y_fake = np.ones((half_batch, 1))\n",
    "                \n",
    "                # Train the critic\n",
    "                if critic == 'Conversion':\n",
    "                    c_loss1 = C.train_on_batch([imr, real_images], y_real)\n",
    "                    c_loss2 = C.train_on_batch([imr, fake_images], y_fake)\n",
    "                    c1_tmp.append(c_loss1)\n",
    "                    c2_tmp.append(c_loss2)\n",
    "                    \n",
    "                else:\n",
    "                    r_loss1 = C.train_on_batch(real_images, y_real)\n",
    "                    r_loss2 = C.train_on_batch(fake_images, y_fake)\n",
    "                    r1_tmp.append(r_loss1)\n",
    "                    r2_tmp.append(r_loss2)\n",
    "            \n",
    "            # Train the Generator\n",
    "            y_gen = -np.ones((batch_size, 1))\n",
    "\n",
    "            if critic == 'Conversion':\n",
    "                g_loss = ConvGAN.train_on_batch([imrs, z_vectors], y_gen)\n",
    "                gc_tmp.append(g_loss)\n",
    "            else:\n",
    "                g_loss = RealGAN.train_on_batch([imrs, z_vectors], y_gen)\n",
    "                gr_tmp.append(g_loss)\n",
    "        \n",
    "        conv1_hist.append(np.mean(c1_tmp))\n",
    "        conv2_hist.append(np.mean(c2_tmp))\n",
    "        real1_hist.append(np.mean(r1_tmp))\n",
    "        real2_hist.append(np.mean(r2_tmp))\n",
    "        gc_hist.append(np.mean(gc_tmp))\n",
    "        gr_hist.append(np.mean(gr_tmp))\n",
    "            \n",
    "        print('epoch %d > conv1=%.3f,        conv2=%.3f,        real1=%.3f,        real2=%.3f,        convgen=%.3f,        realgen=%.3f' % (epoch + 1, conv1_hist[-1], conv2_hist[-1], real1_hist[-1], real2_hist[-1], gc_hist[-1], gr_hist[-1]))\n",
    "        # summarize\n",
    "        if (epoch + 1) % 10 == 0: # (epoch + 1) % 2 == 0\n",
    "            summarize(epoch, generator, conversion_critic, realism_critic, vis_imr, vis_vectors, 10)\n",
    "    plot_history(conv1_hist, conv2_hist, real1_hist, real2_hist, gc_hist, gr_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d017d-9d16-46e4-a2e6-caf571d9eca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Models\n",
    "generator = make_generator()\n",
    "conversion_critic = make_conversion_critic()\n",
    "realism_critic = make_realism_critic()\n",
    "RealGAN = define_RealGAN(generator, realism_critic)\n",
    "ConvGAN = define_ConvGAN(generator, conversion_critic)\n",
    "\n",
    "# Train the GANs\n",
    "vis_path = './Tiles/vis/'\n",
    "vis_IMRS = get_vis_imrs(vis_path)\n",
    "train_GAN(generator, conversion_critic, realism_critic, ConvGAN, RealGAN, vis_IMRS, 0, 50, 2, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2e0c9-0a3c-498c-a5cd-4b13f9c8d653",
   "metadata": {},
   "source": [
    "### **Loading and Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525c009-7ac3-4766-9cf6-531b13889150",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_path = './Model/savedModel/Critics/conv_0050.tf'\n",
    "r_path = './Model/savedModel/Critics/real_0050.tf'\n",
    "g_path = './Model/savedModel/model_0050.tf'\n",
    "c = tf.keras.saving.load_model(c_path, compile=True)\n",
    "r = tf.keras.saving.load_model(r_path, compile=True)\n",
    "g = tf.keras.saving.load_model(g_path)\n",
    "cg = define_ConvGAN(g, c)\n",
    "rg = define_RealGAN(g, r)\n",
    "\n",
    "vis_path = './Tiles/vis/'\n",
    "vis_IMRS = get_vis_imrs(vis_path)\n",
    "\n",
    "# Training Call\n",
    "start_epoch = 60\n",
    "end_epoch = 100\n",
    "train_GAN(g, c, r, cg, rg, vis_IMRS, start_epoch, end_epoch, 2, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
